## thinking
当一个输入可以有多种正确输出时，使用单一目标的交叉熵损失和贪心解码会导致以下问题：

- 损失函数不准确：模型可能生成了一个合理的描述，但因为它与训练集中的特定参考不匹配而受到惩罚
- 训练不稳定：相同输入对应的不同参考可能互相矛盾，导致模型无法收敛
- 评估不公平：贪心解码只能生成一种输出，无法体现模型可能具备的多样性


由于验证集中一条mr可以对应多条 ref：
- val_loss 描述不准确，故去除
- 使用 bleu4 作为验证集指标，但是仍然要解决多条 ref 的问题：模型输入mr得到一个输出，该输出与多条ref计算bleu4，取最高的数值



## explore

关于梯度裁剪clip：
- 梯度裁剪 clip 设置较小的值可以让模型快速收敛，但是后期波动大，可能说明收敛的方向不对（局部最优）
- 梯度裁剪设置较大值或者不设限，那么模型收敛会变慢，并且前期梯度大，更有可能跳出局部极值
- 不进行梯度裁剪可能导致梯度爆炸，不过本次任务是短文本分类，故影响不大

关于teacher forcing：
- 训练时完全使用 teacher forcing 效果还不错
- 但是容易过拟合
- 本次任务如果使用 scheduling， 反倒效果不好（为什么？数据集太小了？）

关于交叉熵损失函数：
- torch的类提供了接口，可以忽略掉 pad 标签的相关损失，可是似乎造成了模型没能正确的认识到eos的含义？

关于掩码注意力和lstm处理填充的batch序列
- 事先准备一个 valid_src_len 是十分有必要的


## 项目结构
e2e_dataset 目录：包含训练集、验证集、测试集的csv文件。
tokenizers 目录：用于保存得到的分词器模型。
train_history 目录：用于保存训练过程中的模型和配置文件。
attention_visualization 目录：用于保存注意力可视化的热力图。
Datasets.py 模块文件：包含数据集处理类 E2Edaraset 等。
myTokenizer.py 模块文件：包含自定义的分词工具类 Tokenizer。
seq2seq.py 模块文件：包含序列生成模型完整定义，包括encoder，decoder，注意力层等。
utils.py 模块文件：包含一些通用的工具函数，如绘图相关函数与重构mr字段的函数。
build_vocab.py 脚本文件：用于构建词汇表和分词器，并且将分词器保存到 tokenizers中。
train_lstm.py 脚本文件：训练模型的脚本，包含训练和验证的逻辑。
lstm_predict.py 脚本文件：包含test逻辑，用于生成测试集的生成结果。
visualize_attentions.py 脚本文件：用于生成注意力可视化热力图。